{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction:\n",
    "\n",
    "This notebook demonstrates -\n",
    "\n",
    "1. Use of DPU and Preprocessing Accelerators to perform AI Inference on live video usb webcam input.\n",
    "2. Option to run different AI models like facedetect, refinedet, and SSD using the same set of accelerators.\n",
    "\n",
    "The application is based on the VVAS (Vitis Video Analytics SDK) framework, also utilizing the open source GStreamer plugins.\n",
    "\n",
    "Vitis Video Analytics SDK (VVAS) is developed by Xilinx to provide many useful GStreamer plugins as the middleware between the application and underlying FPGA accelerators, including DPU AI inference engine, and other PL accelerators such as the one for AI input preprocessing.\n",
    "\n",
    "Please refer to the [Kria™ KV260 Vision AI Starter Kit Applications GitHub Pages](https://xilinx.github.io/kria-apps-docs/index.html) for detailed HW/SW architecture and [Vitis Video Analytics SDK GitHub Pages](https://xilinx.github.io/VVAS/#) for the VVAS related info."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "from IPython.display import *\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import *\n",
    "import time     \n",
    "import glob\n",
    "import gi\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Video Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline flow-\n",
    "\n",
    "The VCU decodes the H264 file to NV12 format.\n",
    "The preprocessing block resizes, quantizes, and converts to BGR format.\n",
    "DPU does the AI inference based on the model selected and generates bounding box data.\n",
    "Meta Affixer scales the bounding box data received wrt the resolution of vcu decoded output.\n",
    "The bounding box draws the results around the objects of interest.\n",
    "\n",
    "PL - Pre-proc, DPU\n",
    "\n",
    "Hardened Block - VCU Dec, Display Port"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If DPU is in slot0 and PP_PIPELINE is in slot1. Copy the dpu_slot0 xclbin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp /lib/firmware/xilinx/k26-dfx-2rp/DPU/DPU_slot0/dpu_RP_0.xclbin /lib/firmware/xilinx/k26-dfx-2rp/DPU\n",
    "! mv /lib/firmware/xilinx/k26-dfx-2rp/DPU/dpu_RP_0.xclbin /lib/firmware/xilinx/k26-dfx-2rp/DPU/dfx-ml-inference.xclbin\n",
    "! cp /lib/firmware/xilinx/k26-dfx-2rp/DPU/DPU_slot0/dpu_RP_0.xclbin /usr/lib\n",
    "! mv /usr/lib/dpu_RP_0.xclbin /usr/lib/dpu.xclbin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If DPU is in slot1 and PP_PIPELINE is in slot0. Copy the dpu_slot1 xclbin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp /lib/firmware/xilinx/k26-dfx-2rp/DPU/DPU_slot1/dpu_RP_1.xclbin /lib/firmware/xilinx/k26-dfx-2rp/DPU\n",
    "! mv /lib/firmware/xilinx/k26-dfx-2rp/DPU/dpu_RP_1.xclbin /lib/firmware/xilinx/k26-dfx-2rp/DPU/dfx-ml-inference.xclbin\n",
    "! cp /lib/firmware/xilinx/k26-dfx-2rp/DPU/DPU_slot1/dpu_RP_1.xclbin /usr/lib\n",
    "! mv /usr/lib/dpu_RP_1.xclbin /usr/lib/dpu.xclbin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Choose AI Inference Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Option to set required AI model"
    "\n",
    "facedetect - Used for face detection \n",
    "\n",
    "refinedet - Used for object detection \n",
    "\n",
    "ssd - Single shot detection used for Object detection"  
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "aitask= [ \"refinedet\",\"facedetect\",\"ssd\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16f9824fe349498dac60943731a77136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='ai_task :', options=('refinedet', 'facedetect', 'ssd'), value='refinedet')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "w = widgets.Dropdown(options=aitask,value=aitask[0],description='ai_task :',)\n",
    "ai_task = aitask[0]\n",
    "def on_change(change):\n",
    "    if change['type'] == 'change' and change['name'] == 'value':\n",
    "        global ai_task \n",
    "        ai_task = change['new']\n",
    "w.observe(on_change)\n",
    "display(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "confdir=\"/opt/xilinx/dfx-ml-inference/vvas/config/\"+ ai_task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Run AI Inference using usb webcam on KV260 board"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function returns the matching media node for a given video capture source. \n",
    "\n",
    "usb webcam: KV260 board requires USB webcam supporting 1920×1080 resolution. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_media_dev_by_name(src):\n",
    "    sources = {\n",
    "        \"usb\" : 'uvcvideo',\n",
    "    }\n",
    "    devices = glob.glob('/dev/media*')\n",
    "    for dev in devices:\n",
    "        proc = subprocess.run(['media-ctl', '-d', dev, '-p'], capture_output=True, encoding='utf8')\n",
    "        for line in proc.stdout.splitlines():\n",
    "            if sources[src] in line:\n",
    "                return dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_dev_of_mediadev(src):\n",
    "    proc = subprocess.Popen(['media-ctl', '-d', src, '-p'], stdout=subprocess.PIPE)\n",
    "    output = subprocess.check_output(('awk', '/^driver\\s*uvcvideo/ {u=1} /device node name *\\/dev\\/video/ {x=$4;f=1;next} u&&f&&/pad0: Sink/ {print x; x=\"\"} f {f=0}'), stdin=proc.stdout).decode('utf8').splitlines()\n",
    "    if len(output) > 1:\n",
    "        return output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "media_device = get_media_dev_by_name(\"usb\") \n",
    "if media_device is None:\n",
    "    raise Exception('Unable to find video source ' + source + '. Make sure the device is plugged in, powered, and the correct platform is used.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "usbmedia=media_device\n",
    "usbvideo=get_video_dev_of_mediadev(usbmedia)\n",
    "src = \"v4l2src name=videosrc device={usbvideo} io-mode=mmap stride-align=256 \".format(usbvideo=usbvideo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline running on Input file on the KV260 board-\n",
    "\n",
    "gst-launch-1.0  {src} ! video/x-raw, width=1920, height=1080 ! videoconvert ! video/x-raw, format=NV12 ! tee name=t0 ! queue ! vvas_xmultisrc kconfig=\"{confdir}/preprocess.json\" ! vvas_xfilter kernels-config=\"{confdir}/aiinference.json\" ! scalem0.sink_master vvas_xmetaaffixer name=scalem0 scalem0.src_master ! fakesink t0. ! queue max-size-buffers=1 leaky=2 ! scalem0.sink_slave_0 scalem0.src_slave_0 ! queue ! vvas_xfilter kernels-config=\"{confdir}/drawresult.json\" ! queue ! kmssink  bus-id=fd4a0000.display sync=false fullscreen-overlay=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gst-launch-1.0 {src} ! video/x-raw, width=1920, height=1080 ! videoconvert ! video/x-raw, format=NV12 ! tee name=t0 ! queue ! vvas_xmultisrc kconfig=\"{confdir}/preprocess.json\" ! vvas_xfilter kernels-config=\"{confdir}/aiinference.json\" ! scalem0.sink_master vvas_xmetaaffixer name=scalem0 scalem0.src_master ! fakesink t0. ! queue max-size-buffers=1 leaky=2 ! scalem0.sink_slave_0 scalem0.src_slave_0 ! queue ! vvas_xfilter kernels-config=\"{confdir}/drawresult.json\" ! queue ! kmssink bus-id=fd4a0000.display sync=false fullscreen-overlay=true > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Run AI Inference using a webcam on KR260 board",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KR260 board requires USB webcam supporting 1024x768. \n",
    "\n",
    "Bounding box will come on the region of interest on the monitor depending upon the chosen model. \n",
    "\n",
    "Pipeline running on Input file on the KR260 board-\n",
    "\n",
    "gst-launch-1.0 autovideosrc device=/dev/video0 ! videoconvert ! video/x-raw, format=NV12 ! tee name=t0 ! queue ! vvas_xmultisrc kconfig=\"{confdir}/preprocess.json\" ! vvas_xfilter kernels-config=\"{confdir}/aiinference.json\" ! scalem0.sink_master vvas_xmetaaffixer name=scalem0 scalem0.src_master ! fakesink t0. ! queue max-size-buffers=1 leaky=2 ! scalem0.sink_slave_0 scalem0.src_slave_0 ! queue ! vvas_xfilter kernels-config=\"{confdir}/drawresult.json\" ! queue ! kmssink  bus-id=fd4a0000.display sync=false fullscreen-overlay=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gst-launch-1.0 autovideosrc device=/dev/video0 ! videoconvert ! video/x-raw, format=NV12 ! tee name=t0 ! queue ! vvas_xmultisrc kconfig=\"{confdir}/preprocess.json\" ! vvas_xfilter kernels-config=\"{confdir}/aiinference.json\" ! scalem0.sink_master vvas_xmetaaffixer name=scalem0 scalem0.src_master ! fakesink t0. ! queue max-size-buffers=1 leaky=2 ! scalem0.sink_slave_0 scalem0.src_slave_0 ! queue ! vvas_xfilter kernels-config=\"{confdir}/drawresult.json\" ! queue ! kmssink bus-id=fd4a0000.display sync=false fullscreen-overlay=true > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Summary\n",
    "The Jupyter application shows how to use two accelerators DPU and PP_PIPELINE in two different slots to do inference on the incoming frames, and draw bound boxing of detected results.\n",
    "Both accelerators work on both slots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>Copyright© 2023 Xilinx</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
